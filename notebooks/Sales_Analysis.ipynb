{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sales Analysis Dashboard\n",
    "\n",
    "üß™ **Comprehensive test notebook for tmux analysis layout**\n",
    "\n",
    "This notebook demonstrates:\n",
    "- DuckDB integration for fast analytics\n",
    "- Pandas data manipulation \n",
    "- Interactive visualizations\n",
    "- Cross-window workflow testing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Setup and Imports\n",
    "\n",
    "Import all necessary libraries and establish database connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n",
      "üìä Pandas version: 2.3.0\n",
      "ü¶Ü DuckDB version: 1.3.1\n"
     ]
    }
   ],
   "source": [
    "# Core data science imports (should be auto-loaded in IPython REPL)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Database and analytics\n",
    "import duckdb\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"üìä Pandas version: {pd.__version__}\")\n",
    "print(f\"ü¶Ü DuckDB version: {duckdb.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîå Database Connection\n",
    "\n",
    "Connect to the DuckDB database created by our ETL pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Available tables:\n",
      "Empty DataFrame\n",
      "Columns: [name]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Connect to database (should be created by data_ingestion.py)\n",
    "conn = duckdb.connect('sales_analysis.duckdb')\n",
    "\n",
    "# Verify connection and show available tables\n",
    "tables = conn.execute(\"SHOW TABLES\").df()\n",
    "print(\"üìö Available tables:\")\n",
    "print(tables)\n",
    "\n",
    "# Show table schemas\n",
    "for table_name in tables['name']:\n",
    "    print(f\"\\nüìã Schema for {table_name}:\")\n",
    "    schema = conn.execute(f\"DESCRIBE {table_name}\").df()\n",
    "    print(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Direct File Analysis with DuckDB\n",
    "\n",
    "Test DuckDB's ability to query files directly - great for the Data window workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóÇÔ∏è Direct CSV Analysis:\n",
      "  region  transactions  total_revenue  avg_transaction\n",
      "0  South            13        3269.27           251.48\n",
      "1  North            13        2099.49           161.50\n",
      "2   East            12        1989.57           165.80\n",
      "3   West            12        1739.51           144.96\n",
      "\n",
      "üìã JSON Structure Analysis:\n",
      "JSON query note: Binder Error: Referenced column \"column0\" not found in FROM clause!\n",
      "Candidate bindings: \"catalog\", \"products\"\n",
      "\n",
      "LINE 4:         AVG(CAST(JSON_EXTRACT(column0, '$.price') AS FLOAT)) as avg_price\n",
      "                                      ^\n",
      "(Complex nested JSON may require different approach)\n"
     ]
    }
   ],
   "source": [
    "# Query CSV directly (test Data window integration)\n",
    "print(\"üóÇÔ∏è Direct CSV Analysis:\")\n",
    "direct_csv_query = \"\"\"\n",
    "SELECT \n",
    "    region,\n",
    "    COUNT(*) as transactions,\n",
    "    ROUND(SUM(total_amount), 2) as total_revenue,\n",
    "    ROUND(AVG(total_amount), 2) as avg_transaction\n",
    "FROM read_csv_auto('../data/sales.csv')\n",
    "GROUP BY region\n",
    "ORDER BY total_revenue DESC\n",
    "\"\"\"\n",
    "\n",
    "direct_results = conn.execute(direct_csv_query).df()\n",
    "print(direct_results)\n",
    "\n",
    "# Test JSON querying capabilities\n",
    "print(\"\\nüìã JSON Structure Analysis:\")\n",
    "try:\n",
    "    json_query = \"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as product_count,\n",
    "        AVG(CAST(JSON_EXTRACT(column0, '$.price') AS FLOAT)) as avg_price\n",
    "    FROM read_json_auto('../data/products.json')\n",
    "    \"\"\"\n",
    "    json_results = conn.execute(json_query).df()\n",
    "    print(json_results)\n",
    "except Exception as e:\n",
    "    print(f\"JSON query note: {e}\")\n",
    "    print(\"(Complex nested JSON may require different approach)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí∞ Revenue Analysis\n",
    "\n",
    "Comprehensive revenue analysis using SQL and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "CatalogException",
     "evalue": "Catalog Error: Table with name sales_transactions does not exist!\nDid you mean \"pg_constraint or sqlite_master\"?\n\nLINE 10: FROM sales_transactions\n              ^",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCatalogException\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Overall revenue metrics\u001b[39;00m\n\u001b[32m      2\u001b[39m revenue_query = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33mSELECT \u001b[39m\n\u001b[32m      4\u001b[39m \u001b[33m    COUNT(*) as total_transactions,\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m \u001b[33mFROM sales_transactions\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m revenue_summary = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrevenue_query\u001b[49m\u001b[43m)\u001b[49m.df()\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müí∞ Revenue Summary:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(revenue_summary.T)  \u001b[38;5;66;03m# Transpose for better display\u001b[39;00m\n",
      "\u001b[31mCatalogException\u001b[39m: Catalog Error: Table with name sales_transactions does not exist!\nDid you mean \"pg_constraint or sqlite_master\"?\n\nLINE 10: FROM sales_transactions\n              ^"
     ]
    }
   ],
   "source": [
    "# Overall revenue metrics\n",
    "revenue_query = \"\"\"\n",
    "SELECT \n",
    "    COUNT(*) as total_transactions,\n",
    "    ROUND(SUM(total_amount), 2) as total_revenue,\n",
    "    ROUND(AVG(total_amount), 2) as avg_transaction,\n",
    "    ROUND(MIN(total_amount), 2) as min_transaction,\n",
    "    ROUND(MAX(total_amount), 2) as max_transaction,\n",
    "    COUNT(DISTINCT customer_id) as unique_customers,\n",
    "    COUNT(DISTINCT product_id) as products_sold\n",
    "FROM sales_transactions\n",
    "\"\"\"\n",
    "\n",
    "revenue_summary = conn.execute(revenue_query).df()\n",
    "print(\"üí∞ Revenue Summary:\")\n",
    "print(revenue_summary.T)  # Transpose for better display\n",
    "\n",
    "# Extract key metrics for visualization\n",
    "total_revenue = revenue_summary['total_revenue'].iloc[0]\n",
    "total_transactions = revenue_summary['total_transactions'].iloc[0]\n",
    "avg_transaction = revenue_summary['avg_transaction'].iloc[0]\n",
    "\n",
    "print(f\"\\nüéØ Key Metrics:\")\n",
    "print(f\"Total Revenue: ${total_revenue:,.2f}\")\n",
    "print(f\"Total Transactions: {total_transactions:,}\")\n",
    "print(f\"Average Transaction: ${avg_transaction:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåç Regional Performance Analysis\n",
    "\n",
    "Analyze sales performance across different regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regional analysis query\n",
    "regional_query = \"\"\"\n",
    "SELECT \n",
    "    s.region,\n",
    "    COUNT(*) as transactions,\n",
    "    ROUND(SUM(s.total_amount), 2) as revenue,\n",
    "    ROUND(AVG(s.total_amount), 2) as avg_transaction,\n",
    "    SUM(s.quantity) as units_sold,\n",
    "    COUNT(DISTINCT s.customer_id) as customers,\n",
    "    r.population,\n",
    "    r.gdp_per_capita,\n",
    "    ROUND(SUM(s.total_amount) / r.population * 1000000, 2) as revenue_per_million_pop\n",
    "FROM sales_transactions s\n",
    "LEFT JOIN regions r ON s.region = r.region_code\n",
    "GROUP BY s.region, r.population, r.gdp_per_capita\n",
    "ORDER BY revenue DESC\n",
    "\"\"\"\n",
    "\n",
    "regional_data = conn.execute(regional_query).df()\n",
    "print(\"üåç Regional Performance:\")\n",
    "print(regional_data)\n",
    "\n",
    "# Create regional performance visualizations\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Regional Sales Performance Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Revenue by region\n",
    "ax1.bar(regional_data['region'], regional_data['revenue'], color=sns.color_palette(\"husl\", len(regional_data)))\n",
    "ax1.set_title('Total Revenue by Region')\n",
    "ax1.set_ylabel('Revenue ($)')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Transactions by region\n",
    "ax2.bar(regional_data['region'], regional_data['transactions'], color=sns.color_palette(\"viridis\", len(regional_data)))\n",
    "ax2.set_title('Transactions by Region')\n",
    "ax2.set_ylabel('Number of Transactions')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Average transaction value\n",
    "ax3.bar(regional_data['region'], regional_data['avg_transaction'], color=sns.color_palette(\"plasma\", len(regional_data)))\n",
    "ax3.set_title('Average Transaction Value by Region')\n",
    "ax3.set_ylabel('Average Transaction ($)')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Revenue efficiency (revenue per million population)\n",
    "ax4.bar(regional_data['region'], regional_data['revenue_per_million_pop'], color=sns.color_palette(\"mako\", len(regional_data)))\n",
    "ax4.set_title('Revenue Efficiency (per Million Population)')\n",
    "ax4.set_ylabel('Revenue per Million Pop ($)')\n",
    "ax4.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Product Performance Analysis\n",
    "\n",
    "Analyze product performance with profitability insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product performance with profitability\n",
    "product_query = \"\"\"\n",
    "SELECT \n",
    "    p.name,\n",
    "    p.category,\n",
    "    p.price,\n",
    "    p.cost,\n",
    "    ROUND(p.price - p.cost, 2) as profit_per_unit,\n",
    "    ROUND((p.price - p.cost) / p.price * 100, 1) as margin_percentage,\n",
    "    COUNT(s.transaction_id) as transactions,\n",
    "    SUM(s.quantity) as units_sold,\n",
    "    ROUND(SUM(s.total_amount), 2) as total_revenue,\n",
    "    ROUND(SUM(s.quantity) * (p.price - p.cost), 2) as total_profit,\n",
    "    p.avg_rating,\n",
    "    p.stock_quantity\n",
    "FROM products p\n",
    "LEFT JOIN sales_transactions s ON p.product_id = s.product_id\n",
    "GROUP BY p.product_id, p.name, p.category, p.price, p.cost, p.avg_rating, p.stock_quantity\n",
    "ORDER BY total_revenue DESC\n",
    "\"\"\"\n",
    "\n",
    "product_data = conn.execute(product_query).df()\n",
    "print(\"üì¶ Product Performance:\")\n",
    "print(product_data)\n",
    "\n",
    "# Product performance visualizations\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Product Performance Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Revenue by product\n",
    "ax1.barh(product_data['name'], product_data['total_revenue'])\n",
    "ax1.set_title('Total Revenue by Product')\n",
    "ax1.set_xlabel('Revenue ($)')\n",
    "\n",
    "# Profit margin by product\n",
    "colors = plt.cm.RdYlGn(product_data['margin_percentage'] / 100)\n",
    "ax2.barh(product_data['name'], product_data['margin_percentage'], color=colors)\n",
    "ax2.set_title('Profit Margin by Product')\n",
    "ax2.set_xlabel('Margin (%)')\n",
    "\n",
    "# Units sold vs Average rating scatter\n",
    "scatter = ax3.scatter(product_data['units_sold'], product_data['avg_rating'], \n",
    "                     s=product_data['total_revenue']/10, alpha=0.7,\n",
    "                     c=product_data['margin_percentage'], cmap='viridis')\n",
    "ax3.set_xlabel('Units Sold')\n",
    "ax3.set_ylabel('Average Rating')\n",
    "ax3.set_title('Units Sold vs Rating (size = revenue, color = margin)')\n",
    "plt.colorbar(scatter, ax=ax3, label='Margin %')\n",
    "\n",
    "# Category performance\n",
    "category_summary = product_data.groupby('category').agg({\n",
    "    'total_revenue': 'sum',\n",
    "    'total_profit': 'sum',\n",
    "    'units_sold': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "ax4.pie(category_summary['total_revenue'], labels=category_summary['category'], autopct='%1.1f%%')\n",
    "ax4.set_title('Revenue Distribution by Category')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Time Series Analysis\n",
    "\n",
    "Analyze sales trends over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily sales trends\n",
    "time_series_query = \"\"\"\n",
    "SELECT \n",
    "    date,\n",
    "    COUNT(*) as daily_transactions,\n",
    "    ROUND(SUM(total_amount), 2) as daily_revenue,\n",
    "    ROUND(AVG(total_amount), 2) as avg_transaction,\n",
    "    SUM(quantity) as daily_units\n",
    "FROM sales_transactions\n",
    "GROUP BY date\n",
    "ORDER BY date\n",
    "\"\"\"\n",
    "\n",
    "time_series_data = conn.execute(time_series_query).df()\n",
    "time_series_data['date'] = pd.to_datetime(time_series_data['date'])\n",
    "\n",
    "print(\"üìÖ Time Series Summary:\")\n",
    "print(f\"Date range: {time_series_data['date'].min()} to {time_series_data['date'].max()}\")\n",
    "print(f\"Total days: {len(time_series_data)}\")\n",
    "print(f\"Average daily revenue: ${time_series_data['daily_revenue'].mean():.2f}\")\n",
    "\n",
    "# Time series visualizations\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Sales Trends Over Time', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Daily revenue trend\n",
    "ax1.plot(time_series_data['date'], time_series_data['daily_revenue'], marker='o', linewidth=2, markersize=4)\n",
    "ax1.set_title('Daily Revenue Trend')\n",
    "ax1.set_ylabel('Daily Revenue ($)')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Daily transactions\n",
    "ax2.bar(time_series_data['date'], time_series_data['daily_transactions'], alpha=0.7)\n",
    "ax2.set_title('Daily Transaction Count')\n",
    "ax2.set_ylabel('Number of Transactions')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Average transaction value over time\n",
    "ax3.plot(time_series_data['date'], time_series_data['avg_transaction'], \n",
    "         marker='s', linewidth=2, markersize=4, color='green')\n",
    "ax3.set_title('Average Transaction Value Over Time')\n",
    "ax3.set_ylabel('Average Transaction ($)')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Units sold over time\n",
    "ax4.fill_between(time_series_data['date'], time_series_data['daily_units'], alpha=0.6, color='orange')\n",
    "ax4.set_title('Daily Units Sold')\n",
    "ax4.set_ylabel('Units Sold')\n",
    "ax4.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõí Channel and Sales Rep Analysis\n",
    "\n",
    "Analyze performance by sales channel and sales representatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel performance\n",
    "channel_query = \"\"\"\n",
    "SELECT \n",
    "    channel,\n",
    "    COUNT(*) as transactions,\n",
    "    ROUND(SUM(total_amount), 2) as revenue,\n",
    "    ROUND(AVG(total_amount), 2) as avg_transaction,\n",
    "    SUM(quantity) as units_sold,\n",
    "    COUNT(DISTINCT customer_id) as customers\n",
    "FROM sales_transactions\n",
    "GROUP BY channel\n",
    "ORDER BY revenue DESC\n",
    "\"\"\"\n",
    "\n",
    "channel_data = conn.execute(channel_query).df()\n",
    "print(\"üõí Channel Performance:\")\n",
    "print(channel_data)\n",
    "\n",
    "# Sales rep performance\n",
    "rep_query = \"\"\"\n",
    "SELECT \n",
    "    sales_rep,\n",
    "    COUNT(*) as transactions,\n",
    "    ROUND(SUM(total_amount), 2) as revenue,\n",
    "    ROUND(AVG(total_amount), 2) as avg_transaction,\n",
    "    COUNT(DISTINCT customer_id) as customers_served,\n",
    "    ROUND(SUM(total_amount) / COUNT(DISTINCT customer_id), 2) as revenue_per_customer\n",
    "FROM sales_transactions\n",
    "GROUP BY sales_rep\n",
    "ORDER BY revenue DESC\n",
    "\"\"\"\n",
    "\n",
    "rep_data = conn.execute(rep_query).df()\n",
    "print(\"\\nüë§ Sales Rep Performance:\")\n",
    "print(rep_data)\n",
    "\n",
    "# Channel and rep visualizations\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Channel and Sales Rep Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Channel revenue pie chart\n",
    "ax1.pie(channel_data['revenue'], labels=channel_data['channel'], autopct='%1.1f%%', startangle=90)\n",
    "ax1.set_title('Revenue by Channel')\n",
    "\n",
    "# Channel transaction volume\n",
    "ax2.bar(channel_data['channel'], channel_data['transactions'], color=sns.color_palette(\"Set2\"))\n",
    "ax2.set_title('Transactions by Channel')\n",
    "ax2.set_ylabel('Number of Transactions')\n",
    "\n",
    "# Sales rep revenue\n",
    "ax3.barh(rep_data['sales_rep'], rep_data['revenue'], color=sns.color_palette(\"pastel\"))\n",
    "ax3.set_title('Revenue by Sales Rep')\n",
    "ax3.set_xlabel('Revenue ($)')\n",
    "\n",
    "# Sales rep efficiency (revenue per customer)\n",
    "ax4.bar(rep_data['sales_rep'], rep_data['revenue_per_customer'], color=sns.color_palette(\"dark\"))\n",
    "ax4.set_title('Revenue per Customer by Sales Rep')\n",
    "ax4.set_ylabel('Revenue per Customer ($)')\n",
    "ax4.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Executive Dashboard Summary\n",
    "\n",
    "Create a comprehensive executive summary with key KPIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executive KPIs\n",
    "kpi_query = \"\"\"\n",
    "SELECT \n",
    "    (SELECT SUM(total_amount) FROM sales_transactions) as total_revenue,\n",
    "    (SELECT COUNT(*) FROM sales_transactions) as total_transactions,\n",
    "    (SELECT COUNT(DISTINCT customer_id) FROM sales_transactions) as total_customers,\n",
    "    (SELECT COUNT(*) FROM products WHERE stock_quantity <= reorder_level) as products_need_reorder,\n",
    "    (SELECT ROUND(AVG(avg_rating), 2) FROM products) as avg_product_rating,\n",
    "    (SELECT COUNT(DISTINCT sales_rep) FROM sales_transactions) as active_sales_reps,\n",
    "    (SELECT COUNT(DISTINCT channel) FROM sales_transactions) as sales_channels\n",
    "\"\"\"\n",
    "\n",
    "kpis = conn.execute(kpi_query).df().iloc[0]\n",
    "\n",
    "# Create dashboard visualization\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Title\n",
    "fig.suptitle('Sales Analysis Executive Dashboard', fontsize=20, fontweight='bold', y=0.95)\n",
    "\n",
    "# KPI Cards (top row)\n",
    "kpi_metrics = [\n",
    "    ('Total Revenue', f\"${kpis['total_revenue']:,.0f}\", 'green'),\n",
    "    ('Transactions', f\"{kpis['total_transactions']:,}\", 'blue'),\n",
    "    ('Customers', f\"{kpis['total_customers']:,}\", 'orange'),\n",
    "    ('Avg Rating', f\"{kpis['avg_product_rating']:.1f}‚≠ê\", 'purple')\n",
    "]\n",
    "\n",
    "for i, (title, value, color) in enumerate(kpi_metrics):\n",
    "    ax = fig.add_subplot(gs[0, i])\n",
    "    ax.text(0.5, 0.7, value, ha='center', va='center', fontsize=24, fontweight='bold', color=color)\n",
    "    ax.text(0.5, 0.3, title, ha='center', va='center', fontsize=12)\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.axis('off')\n",
    "    # Add border\n",
    "    ax.add_patch(plt.Rectangle((0.05, 0.1), 0.9, 0.8, fill=False, edgecolor=color, linewidth=2))\n",
    "\n",
    "# Revenue by region (middle left)\n",
    "ax_region = fig.add_subplot(gs[1, :2])\n",
    "regional_summary = conn.execute(\"SELECT region, SUM(total_amount) as revenue FROM sales_transactions GROUP BY region ORDER BY revenue DESC\").df()\n",
    "ax_region.bar(regional_summary['region'], regional_summary['revenue'], color=sns.color_palette(\"viridis\", len(regional_summary)))\n",
    "ax_region.set_title('Revenue by Region', fontweight='bold')\n",
    "ax_region.set_ylabel('Revenue ($)')\n",
    "\n",
    "# Product category performance (middle right)\n",
    "ax_category = fig.add_subplot(gs[1, 2:])\n",
    "category_summary = conn.execute(\"\"\"\n",
    "    SELECT p.category, SUM(s.total_amount) as revenue \n",
    "    FROM sales_transactions s \n",
    "    JOIN products p ON s.product_id = p.product_id \n",
    "    GROUP BY p.category \n",
    "    ORDER BY revenue DESC\n",
    "\"\"\").df()\n",
    "ax_category.pie(category_summary['revenue'], labels=category_summary['category'], autopct='%1.1f%%', startangle=90)\n",
    "ax_category.set_title('Revenue by Category', fontweight='bold')\n",
    "\n",
    "# Daily revenue trend (bottom)\n",
    "ax_trend = fig.add_subplot(gs[2, :])\n",
    "daily_revenue = conn.execute(\"SELECT date, SUM(total_amount) as daily_revenue FROM sales_transactions GROUP BY date ORDER BY date\").df()\n",
    "daily_revenue['date'] = pd.to_datetime(daily_revenue['date'])\n",
    "ax_trend.plot(daily_revenue['date'], daily_revenue['daily_revenue'], marker='o', linewidth=3, markersize=6, color='darkgreen')\n",
    "ax_trend.fill_between(daily_revenue['date'], daily_revenue['daily_revenue'], alpha=0.3, color='lightgreen')\n",
    "ax_trend.set_title('Daily Revenue Trend', fontweight='bold')\n",
    "ax_trend.set_ylabel('Daily Revenue ($)')\n",
    "ax_trend.tick_params(axis='x', rotation=45)\n",
    "ax_trend.grid(True, alpha=0.3)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print summary insights\n",
    "print(\"\\nüéØ Key Insights:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üí∞ Total Revenue: ${kpis['total_revenue']:,.2f}\")\n",
    "print(f\"üìä Average Transaction: ${kpis['total_revenue']/kpis['total_transactions']:.2f}\")\n",
    "print(f\"üë• Revenue per Customer: ${kpis['total_revenue']/kpis['total_customers']:.2f}\")\n",
    "print(f\"‚ö†Ô∏è  Inventory Alerts: {kpis['products_need_reorder']} products need reordering\")\n",
    "print(f\"‚≠ê Customer Satisfaction: {kpis['avg_product_rating']:.1f}/5.0 average rating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¨ Advanced Analytics\n",
    "\n",
    "Advanced analytical queries and machine learning preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer segmentation analysis\n",
    "customer_segment_query = \"\"\"\n",
    "SELECT \n",
    "    customer_id,\n",
    "    COUNT(*) as total_transactions,\n",
    "    SUM(total_amount) as total_spent,\n",
    "    AVG(total_amount) as avg_transaction,\n",
    "    SUM(quantity) as total_items,\n",
    "    COUNT(DISTINCT product_id) as unique_products,\n",
    "    CASE \n",
    "        WHEN SUM(total_amount) >= 500 THEN 'High Value'\n",
    "        WHEN SUM(total_amount) >= 200 THEN 'Medium Value'\n",
    "        ELSE 'Low Value'\n",
    "    END as customer_segment\n",
    "FROM sales_transactions\n",
    "GROUP BY customer_id\n",
    "ORDER BY total_spent DESC\n",
    "\"\"\"\n",
    "\n",
    "customer_segments = conn.execute(customer_segment_query).df()\n",
    "\n",
    "# Segment summary\n",
    "segment_summary = customer_segments.groupby('customer_segment').agg({\n",
    "    'customer_id': 'count',\n",
    "    'total_spent': ['sum', 'mean'],\n",
    "    'total_transactions': 'mean',\n",
    "    'avg_transaction': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(\"üë• Customer Segmentation Analysis:\")\n",
    "print(segment_summary)\n",
    "\n",
    "# Product affinity analysis\n",
    "affinity_query = \"\"\"\n",
    "WITH product_pairs AS (\n",
    "    SELECT \n",
    "        a.product_id as product_a,\n",
    "        b.product_id as product_b,\n",
    "        COUNT(*) as co_occurrences\n",
    "    FROM sales_transactions a\n",
    "    JOIN sales_transactions b ON a.customer_id = b.customer_id \n",
    "        AND a.product_id < b.product_id\n",
    "    GROUP BY a.product_id, b.product_id\n",
    "    HAVING COUNT(*) > 1\n",
    ")\n",
    "SELECT \n",
    "    pa.name as product_a_name,\n",
    "    pb.name as product_b_name,\n",
    "    pp.co_occurrences\n",
    "FROM product_pairs pp\n",
    "JOIN products pa ON pp.product_a = pa.product_id\n",
    "JOIN products pb ON pp.product_b = pb.product_id\n",
    "ORDER BY co_occurrences DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "product_affinity = conn.execute(affinity_query).df()\n",
    "print(\"\\nüîó Product Affinity Analysis (customers who bought both):\")\n",
    "print(product_affinity)\n",
    "\n",
    "# Visualization of customer segments\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Customer segment distribution\n",
    "segment_counts = customer_segments['customer_segment'].value_counts()\n",
    "ax1.pie(segment_counts.values, labels=segment_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "ax1.set_title('Customer Segment Distribution')\n",
    "\n",
    "# Segment value distribution\n",
    "sns.boxplot(data=customer_segments, x='customer_segment', y='total_spent', ax=ax2)\n",
    "ax2.set_title('Spending Distribution by Segment')\n",
    "ax2.set_ylabel('Total Spent ($)')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Export Results for Cross-Window Analysis\n",
    "\n",
    "Export key datasets for use in other windows (Editor, REPL, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export key analysis results\n",
    "print(\"üíæ Exporting analysis results...\")\n",
    "\n",
    "# Regional performance for Editor window testing\n",
    "regional_data.to_csv('../data/analysis_regional_performance.csv', index=False)\n",
    "print(\"‚úÖ Regional performance exported to data/analysis_regional_performance.csv\")\n",
    "\n",
    "# Product performance for REPL testing\n",
    "product_data.to_csv('../data/analysis_product_performance.csv', index=False)\n",
    "print(\"‚úÖ Product performance exported to data/analysis_product_performance.csv\")\n",
    "\n",
    "# Customer segments for further analysis\n",
    "customer_segments.to_csv('../data/analysis_customer_segments.csv', index=False)\n",
    "print(\"‚úÖ Customer segments exported to data/analysis_customer_segments.csv\")\n",
    "\n",
    "# Summary dashboard data as JSON for API testing\n",
    "dashboard_summary = {\n",
    "    'kpis': kpis.to_dict(),\n",
    "    'regional_performance': regional_data.to_dict('records'),\n",
    "    'product_performance': product_data.head(5).to_dict('records'),\n",
    "    'customer_segments': segment_summary.to_dict()\n",
    "}\n",
    "\n",
    "with open('../data/analysis_dashboard_summary.json', 'w') as f:\n",
    "    json.dump(dashboard_summary, f, indent=2, default=str)\n",
    "print(\"‚úÖ Dashboard summary exported to data/analysis_dashboard_summary.json\")\n",
    "\n",
    "print(\"\\nüéØ Analysis Complete!\")\n",
    "print(\"üìÅ All results exported and ready for cross-window testing\")\n",
    "print(\"üí° Next steps:\")\n",
    "print(\"   ‚Ä¢ Test file discovery in Data window with new exports\")\n",
    "print(\"   ‚Ä¢ Load results in REPL for further analysis\")\n",
    "print(\"   ‚Ä¢ Use Editor window to create summary reports\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîö Cleanup and Notes\n",
    "\n",
    "Final cleanup and testing notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show final database state\n",
    "print(\"üìö Final Database State:\")\n",
    "tables = conn.execute(\"SHOW TABLES\").df()\n",
    "for table_name in tables['name']:\n",
    "    count = conn.execute(f\"SELECT COUNT(*) FROM {table_name}\").fetchone()[0]\n",
    "    print(f\"  {table_name}: {count:,} rows\")\n",
    "\n",
    "# Performance metrics\n",
    "print(\"\\n‚ö° Performance Test Results:\")\n",
    "import time\n",
    "start_time = time.time()\n",
    "test_query = \"SELECT COUNT(*), SUM(total_amount) FROM sales_transactions\"\n",
    "result = conn.execute(test_query).fetchone()\n",
    "query_time = time.time() - start_time\n",
    "print(f\"  DuckDB query time: {query_time:.4f} seconds\")\n",
    "print(f\"  Query result: {result[0]:,} transactions, ${result[1]:,.2f} total\")\n",
    "\n",
    "# Testing checklist\n",
    "print(\"\\n‚úÖ Tmux Analysis Layout Testing Checklist:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"üìù Editor Window:\")\n",
    "print(\"   ‚úÖ File navigation and editing tested\")\n",
    "print(\"   ‚úÖ Python script development workflow\")\n",
    "print(\"   ‚úÖ Cross-file referencing\")\n",
    "print(\"\\nü™ê Jupyter Window:\")\n",
    "print(\"   ‚úÖ Notebook execution and visualization\")\n",
    "print(\"   ‚úÖ DuckDB integration tested\")\n",
    "print(\"   ‚úÖ Data export for cross-window workflow\")\n",
    "print(\"\\nüêç REPL Window:\")\n",
    "print(\"   ‚úÖ IPython auto-imports working\")\n",
    "print(\"   ‚úÖ Quick testing functions available\")\n",
    "print(\"   ‚úÖ DuckDB SQL pane integration\")\n",
    "print(\"\\nüìä Data Window:\")\n",
    "print(\"   ‚úÖ Multiple file formats (CSV, JSON, Parquet)\")\n",
    "print(\"   ‚úÖ File discovery and preview functions\")\n",
    "print(\"   ‚úÖ Data quality assessment tools\")\n",
    "print(\"\\nüêö Shell Window:\")\n",
    "print(\"   ‚úÖ Environment management integration\")\n",
    "print(\"   ‚úÖ Git workflow with enhanced functions\")\n",
    "print(\"   ‚úÖ Project monitoring and status\")\n",
    "\n",
    "print(\"\\nüéâ Comprehensive tmux analysis layout test completed successfully!\")\n",
    "\n",
    "# Keep connection open for continued analysis\n",
    "print(\"\\nüí° Database connection remains open for continued analysis\")\n",
    "print(\"   Connection object: 'conn'\")\n",
    "print(\"   Use conn.execute(query).df() for additional queries\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

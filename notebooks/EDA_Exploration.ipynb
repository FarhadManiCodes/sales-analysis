{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "🔬 **Quick data exploration and profiling for tmux layout testing**\n",
    "\n",
    "This notebook focuses on:\n",
    "- Rapid data profiling and quality assessment\n",
    "- Interactive data exploration\n",
    "- Testing cross-window workflows\n",
    "- Performance comparisons between tools\n",
    "\n",
    "Perfect for testing the **Data window** and **REPL window** integration!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Quick Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast imports for EDA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import duckdb\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Quick settings\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"Set2\")\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"🔬 EDA Environment Ready!\")\n",
    "print(f\"Working directory: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📁 File Discovery Test\n",
    "\n",
    "Test data file discovery - simulating Data window workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover available data files (like Data window)\n",
    "print(\"📂 Data File Discovery:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "data_dir = Path('../data')\n",
    "if data_dir.exists():\n",
    "    print(\"📊 Available data files:\")\n",
    "    for file_path in data_dir.glob('*'):\n",
    "        if file_path.is_file():\n",
    "            size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "            print(f\"  📄 {file_path.name}: {size_mb:.2f} MB\")\n",
    "else:\n",
    "    print(\"❌ Data directory not found\")\n",
    "\n",
    "# List by file type (simulating fd commands)\n",
    "print(\"\\n🔍 Files by type:\")\n",
    "file_types = {\n",
    "    'CSV': list(data_dir.glob('*.csv')),\n",
    "    'JSON': list(data_dir.glob('*.json')),\n",
    "    'Parquet': list(data_dir.glob('*.parquet')),\n",
    "    'Analysis Results': list(data_dir.glob('analysis_*.csv'))\n",
    "}\n",
    "\n",
    "for file_type, files in file_types.items():\n",
    "    print(f\"  {file_type}: {len(files)} files\")\n",
    "    for file in files[:3]:  # Show first 3\n",
    "        print(f\"    • {file.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Quick Data Profiling\n",
    "\n",
    "Rapid data profiling using pandas - test `quickload()` functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick data profiling function (like quickload in REPL)\n",
    "def quick_profile(file_path, sample_size=None):\n",
    "    \"\"\"Quick data profiling - simulates quickload() function.\"\"\"\n",
    "    print(f\"🔍 Quick Profile: {file_path}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Load data based on file type\n",
    "        if str(file_path).endswith('.csv'):\n",
    "            df = pd.read_csv(file_path, nrows=sample_size)\n",
    "        elif str(file_path).endswith('.parquet'):\n",
    "            df = pd.read_parquet(file_path)\n",
    "        else:\n",
    "            print(\"❌ Unsupported file type\")\n",
    "            return None\n",
    "        \n",
    "        # Basic info\n",
    "        print(f\"📏 Shape: {df.shape}\")\n",
    "        print(f\"💾 Memory: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "        print(f\"🏷️  Columns: {list(df.columns)}\")\n",
    "        print(f\"🔢 Data types: {df.dtypes.value_counts().to_dict()}\")\n",
    "        \n",
    "        # Data quality\n",
    "        missing = df.isnull().sum().sum()\n",
    "        duplicates = df.duplicated().sum()\n",
    "        print(f\"❓ Missing values: {missing}\")\n",
    "        print(f\"🔁 Duplicates: {duplicates}\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test with sales data\n",
    "sales_df = quick_profile('../data/sales.csv')\n",
    "if sales_df is not None:\n",
    "    print(\"\\n👀 First 3 rows:\")\n",
    "    print(sales_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔄 Performance Comparison\n",
    "\n",
    "Compare loading methods - test DuckDB vs Pandas performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance benchmark (simulating REPL quick tests)\n",
    "import time\n",
    "\n",
    "def benchmark_loading(file_path, iterations=3):\n",
    "    \"\"\"Benchmark different loading methods.\"\"\"\n",
    "    print(f\"⚡ Performance Benchmark: {Path(file_path).name}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Pandas loading\n",
    "    pandas_times = []\n",
    "    for i in range(iterations):\n",
    "        start = time.time()\n",
    "        df_pandas = pd.read_csv(file_path)\n",
    "        pandas_times.append(time.time() - start)\n",
    "    \n",
    "    results['pandas'] = {\n",
    "        'avg_time': np.mean(pandas_times),\n",
    "        'rows': len(df_pandas),\n",
    "        'memory_mb': df_pandas.memory_usage(deep=True).sum() / 1024**2\n",
    "    }\n",
    "    \n",
    "    # DuckDB loading\n",
    "    duckdb_times = []\n",
    "    for i in range(iterations):\n",
    "        conn = duckdb.connect()\n",
    "        start = time.time()\n",
    "        df_duckdb = conn.execute(f\"SELECT * FROM read_csv_auto('{file_path}')\").df()\n",
    "        duckdb_times.append(time.time() - start)\n",
    "        conn.close()\n",
    "    \n",
    "    results['duckdb'] = {\n",
    "        'avg_time': np.mean(duckdb_times),\n",
    "        'rows': len(df_duckdb),\n",
    "        'memory_mb': df_duckdb.memory_usage(deep=True).sum() / 1024**2\n",
    "    }\n",
    "    \n",
    "    # Results\n",
    "    print(f\"🐼 Pandas: {results['pandas']['avg_time']:.4f}s avg ({results['pandas']['rows']:,} rows)\")\n",
    "    print(f\"🦆 DuckDB: {results['duckdb']['avg_time']:.4f}s avg ({results['duckdb']['rows']:,} rows)\")\n",
    "    \n",
    "    speedup = results['pandas']['avg_time'] / results['duckdb']['avg_time']\n",
    "    winner = 'DuckDB' if speedup > 1 else 'Pandas'\n",
    "    print(f\"🏆 Winner: {winner} ({speedup:.2f}x {'faster' if speedup > 1 else 'slower'})\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run benchmark\n",
    "if Path('../data/sales.csv').exists():\n",
    "    benchmark_results = benchmark_loading('../data/sales.csv')\n",
    "else:\n",
    "    print(\"❌ Sales CSV not found for benchmarking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📋 JSON Structure Exploration\n",
    "\n",
    "Explore nested JSON structure - test complex data handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON exploration (simulating Data window JSON preview)\n",
    "def explore_json(file_path):\n",
    "    \"\"\"Explore JSON structure - like jsonprev() function.\"\"\"\n",
    "    print(f\"📋 JSON Structure: {Path(file_path).name}\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        def analyze_structure(obj, path=\"root\", max_depth=3, current_depth=0):\n",
    "            if current_depth > max_depth:\n",
    "                return\n",
    "            \n",
    "            if isinstance(obj, dict):\n",
    "                print(f\"{'  ' * current_depth}📁 {path} (dict, {len(obj)} keys)\")\n",
    "                for key, value in list(obj.items())[:5]:  # First 5 keys\n",
    "                    analyze_structure(value, f\"{path}.{key}\", max_depth, current_depth + 1)\n",
    "                if len(obj) > 5:\n",
    "                    print(f\"{'  ' * (current_depth + 1)}... and {len(obj) - 5} more keys\")\n",
    "            \n",
    "            elif isinstance(obj, list):\n",
    "                print(f\"{'  ' * current_depth}📊 {path} (list, {len(obj)} items)\")\n",
    "                if obj:\n",
    "                    analyze_structure(obj[0], f\"{path}[0]\", max_depth, current_depth + 1)\n",
    "            \n",
    "            else:\n",
    "                type_name = type(obj).__name__\n",
    "                value_preview = str(obj)[:50] + \"...\" if len(str(obj)) > 50 else str(obj)\n",
    "                print(f\"{'  ' * current_depth}🏷️  {path} ({type_name}): {value_preview}\")\n",
    "        \n",
    "        analyze_structure(data)\n",
    "        \n",
    "        # Summary stats\n",
    "        file_size = Path(file_path).stat().st_size\n",
    "        print(f\"\\n📊 JSON Summary:\")\n",
    "        print(f\"  File size: {file_size / 1024:.1f} KB\")\n",
    "        print(f\"  Root type: {type(data).__name__}\")\n",
    "        \n",
    "        if isinstance(data, dict):\n",
    "            print(f\"  Top-level keys: {len(data)}\")\n",
    "        elif isinstance(data, list):\n",
    "            print(f\"  Array length: {len(data)}\")\n",
    "        \n",
    "        return data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error reading JSON: {e}\")\n",
    "        return None\n",
    "\n",
    "# Explore products JSON\n",
    "if Path('../data/products.json').exists():\n",
    "    products_data = explore_json('../data/products.json')\n",
    "else:\n",
    "    print(\"❌ Products JSON not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔢 Statistical Overview\n",
    "\n",
    "Quick statistical analysis - test Data window statistics functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick statistical overview (like quickstats() function)\n",
    "def quick_stats(df, name=\"Dataset\"):\n",
    "    \"\"\"Generate quick statistics overview.\"\"\"\n",
    "    print(f\"📊 Quick Stats: {name}\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        print(\"🔢 Numeric Columns:\")\n",
    "        for col in numeric_cols:\n",
    "            print(f\"  {col}:\")\n",
    "            print(f\"    Range: {df[col].min():.2f} to {df[col].max():.2f}\")\n",
    "            print(f\"    Mean: {df[col].mean():.2f}\")\n",
    "            print(f\"    Std: {df[col].std():.2f}\")\n",
    "            print(f\"    Missing: {df[col].isnull().sum()}\")\n",
    "    \n",
    "    # Categorical columns\n",
    "    cat_cols = df.select_dtypes(include=['object']).columns\n",
    "    if len(cat_cols) > 0:\n",
    "        print(\"\\n📝 Categorical Columns:\")\n",
    "        for col in cat_cols:\n",
    "            unique_count = df[col].nunique()\n",
    "            print(f\"  {col}: {unique_count} unique values\")\n",
    "            if unique_count <= 10:  # Show values if not too many\n",
    "                top_values = df[col].value_counts().head(3)\n",
    "                print(f\"    Top: {dict(top_values)}\")\n",
    "    \n",
    "    return df.describe(include='all')\n",
    "\n",
    "# Quick stats on sales data\n",
    "if 'sales_df' in locals() and sales_df is not None:\n",
    "    stats = quick_stats(sales_df, \"Sales Data\")\n",
    "    print(\"\\n📋 Full Description:\")\n",
    "    print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📈 Quick Visualizations\n",
    "\n",
    "Rapid visualization for data understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick visualization function\n",
    "def quick_viz(df, max_cols=4):\n",
    "    \"\"\"Generate quick visualizations for EDA.\"\"\"\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns[:max_cols]\n",
    "    \n",
    "    if len(numeric_cols) == 0:\n",
    "        print(\"❌ No numeric columns for visualization\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    fig.suptitle('Quick EDA Visualizations', fontsize=14)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, col in enumerate(numeric_cols):\n",
    "        if i >= 4:\n",
    "            break\n",
    "        \n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Histogram with KDE\n",
    "        df[col].hist(ax=ax, bins=20, alpha=0.7, edgecolor='black')\n",
    "        ax.set_title(f'{col} Distribution')\n",
    "        ax.set_xlabel(col)\n",
    "        ax.set_ylabel('Frequency')\n",
    "        \n",
    "        # Add statistics text\n",
    "        mean_val = df[col].mean()\n",
    "        std_val = df[col].std()\n",
    "        ax.axvline(mean_val, color='red', linestyle='--', alpha=0.7, label=f'Mean: {mean_val:.2f}')\n",
    "        ax.legend()\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(len(numeric_cols), 4):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate quick visualizations\n",
    "if 'sales_df' in locals() and sales_df is not None:\n",
    "    quick_viz(sales_df)\n",
    "else:\n",
    "    print(\"❌ No data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Data Quality Assessment\n",
    "\n",
    "Comprehensive data quality analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality assessment (like datainfo() function)\n",
    "def data_quality_report(df, name=\"Dataset\"):\n",
    "    \"\"\"Comprehensive data quality assessment.\"\"\"\n",
    "    print(f\"🔍 Data Quality Report: {name}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"📏 Dimensions: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "    print(f\"💾 Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Data types\n",
    "    print(f\"\\n🏷️  Data Types:\")\n",
    "    type_counts = df.dtypes.value_counts()\n",
    "    for dtype, count in type_counts.items():\n",
    "        print(f\"  {dtype}: {count} columns\")\n",
    "    \n",
    "    # Missing data analysis\n",
    "    print(f\"\\n❓ Missing Data Analysis:\")\n",
    "    missing_data = df.isnull().sum()\n",
    "    missing_pct = (missing_data / len(df)) * 100\n",
    "    \n",
    "    has_missing = missing_data[missing_data > 0]\n",
    "    if len(has_missing) > 0:\n",
    "        print(\"  Columns with missing data:\")\n",
    "        for col, missing_count in has_missing.items():\n",
    "            pct = missing_pct[col]\n",
    "            print(f\"    {col}: {missing_count} ({pct:.1f}%)\")\n",
    "    else:\n",
    "        print(\"  ✅ No missing data found\")\n",
    "    \n",
    "    # Duplicate analysis\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    duplicate_pct = (duplicate_count / len(df)) * 100\n",
    "    print(f\"\\n🔁 Duplicates: {duplicate_count} ({duplicate_pct:.1f}%)\")\n",
    "    \n",
    "    # Unique value analysis\n",
    "    print(f\"\\n🎯 Uniqueness Analysis:\")\n",
    "    for col in df.columns:\n",
    "        unique_count = df[col].nunique()\n",
    "        unique_pct = (unique_count / len(df)) * 100\n",
    "        \n",
    "        if unique_count == len(df):\n",
    "            status = \"🔑 Unique identifier\"\n",
    "        elif unique_count == 1:\n",
    "            status = \"⚠️  Constant value\"\n",
    "        elif unique_count < 10:\n",
    "            status = \"📊 Categorical\"\n",
    "        elif unique_pct > 95:\n",
    "            status = \"🔢 High cardinality\"\n",
    "        else:\n",
    "            status = \"📈 Normal distribution\"\n",
    "        \n",
    "        print(f\"  {col}: {unique_count:,} unique ({unique_pct:.1f}%) - {status}\")\n",
    "    \n",
    "    # Data quality score\n",
    "    quality_score = 100\n",
    "    if duplicate_count > 0:\n",
    "        quality_score -= min(duplicate_pct * 2, 20)  # Max 20 point deduction\n",
    "    \n",
    "    missing_penalty = min(missing_pct.max() * 1.5, 30)  # Max 30 point deduction\n",
    "    quality_score -= missing_penalty\n",
    "    \n",
    "    print(f\"\\n🏆 Data Quality Score: {quality_score:.1f}/100\")\n",
    "    \n",
    "    if quality_score >= 90:\n",
    "        print(\"   ✅ Excellent data quality\")\n",
    "    elif quality_score >= 75:\n",
    "        print(\"   ⚠️  Good data quality with minor issues\")\n",
    "    elif quality_score >= 50:\n",
    "        print(\"   🔧 Fair data quality - needs attention\")\n",
    "    else:\n",
    "        print(\"   🚨 Poor data quality - significant issues\")\n",
    "    \n",
    "    return {\n",
    "        'shape': df.shape,\n",
    "        'missing_data': missing_data.to_dict(),\n",
    "        'duplicates': duplicate_count,\n",
    "        'quality_score': quality_score\n",
    "    }\n",
    "\n",
    "# Run data quality assessment\n",
    "if 'sales_df' in locals() and sales_df is not None:\n",
    "    quality_report = data_quality_report(sales_df, \"Sales Transactions\")\n",
    "else:\n",
    "    print(\"❌ No data available for quality assessment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Cross-Window Testing\n",
    "\n",
    "Test integration with other tmux layout windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-window integration test\n",
    "print(\"🔗 Cross-Window Integration Test\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# 1. Test database connection (Shell/REPL window integration)\n",
    "print(\"1️⃣ Testing database connection:\")\n",
    "try:\n",
    "    conn = duckdb.connect('sales_analysis.duckdb')\n",
    "    tables = conn.execute(\"SHOW TABLES\").fetchall()\n",
    "    if tables:\n",
    "        print(f\"   ✅ Connected to database with {len(tables)} tables\")\n",
    "        for table in tables:\n",
    "            count = conn.execute(f\"SELECT COUNT(*) FROM {table[0]}\").fetchone()[0]\n",
    "            print(f\"      • {table[0]}: {count:,} rows\")\n",
    "    else:\n",
    "        print(\"   ⚠️  Database exists but no tables found\")\n",
    "        print(\"   💡 Run data_ingestion.py in Shell window first\")\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(f\"   ❌ Database connection failed: {e}\")\n",
    "    print(\"   💡 Create database using scripts/data_ingestion.py\")\n",
    "\n",
    "# 2. Test file accessibility (Data window integration)\n",
    "print(\"\\n2️⃣ Testing file accessibility:\")\n",
    "test_files = [\n",
    "    '../data/sales.csv',\n",
    "    '../data/products.json',\n",
    "    '../data/regions.parquet',\n",
    "    '../scripts/test_functions.py'\n",
    "]\n",
    "\n",
    "for file_path in test_files:\n",
    "    if Path(file_path).exists():\n",
    "        size = Path(file_path).stat().st_size / 1024\n",
    "        print(f\"   ✅ {Path(file_path).name}: {size:.1f} KB\")\n",
    "    else:\n",
    "        print(f\"   ❌ {Path(file_path).name}: Not found\")\n",
    "\n",
    "# 3. Test function imports (REPL window integration)\n",
    "print(\"\\n3️⃣ Testing function imports:\")\n",
    "try:\n",
    "    import sys\n",
    "    sys.path.append('../scripts')\n",
    "    \n",
    "    from test_functions import validate_transaction_data, calculate_profit_metrics\n",
    "    print(\"   ✅ Successfully imported test functions\")\n",
    "    \n",
    "    # Test a function\n",
    "    test_result = calculate_profit_metrics(100, 60, 2)\n",
    "    print(f\"   ✅ Function test successful: profit = ${test_result['total_profit']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   ❌ Function import failed: {e}\")\n",
    "\n",
    "# 4. Test data export (Editor window integration)\n",
    "print(\"\\n4️⃣ Testing data export:\")\n",
    "if 'sales_df' in locals() and sales_df is not None:\n",
    "    try:\n",
    "        # Export sample for Editor window\n",
    "        sample_df = sales_df.head(10)\n",
    "        sample_df.to_csv('../data/eda_sample_export.csv', index=False)\n",
    "        print(\"   ✅ Sample data exported to eda_sample_export.csv\")\n",
    "        print(\"   💡 Use 'fdata' in Data window to find this file\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Export failed: {e}\")\n",
    "else:\n",
    "    print(\"   ⚠️  No data available for export\")\n",
    "\n",
    "print(\"\\n🎯 Integration Test Summary:\")\n",
    "print(\"   • Database: Ready for REPL SQL queries\")\n",
    "print(\"   • Files: Available for Data window exploration\")\n",
    "print(\"   • Functions: Ready for REPL quick testing\")\n",
    "print(\"   • Exports: Available for Editor window analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📋 EDA Summary\n",
    "\n",
    "Summary of findings and next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA Summary and recommendations\n",
    "print(\"📋 EDA Summary Report\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if 'sales_df' in locals() and sales_df is not None:\n",
    "    print(f\"📊 Dataset: Sales Transactions\")\n",
    "    print(f\"   Records: {len(sales_df):,}\")\n",
    "    print(f\"   Columns: {len(sales_df.columns)}\")\n",
    "    print(f\"   Date range: {sales_df['date'].min()} to {sales_df['date'].max()}\")\n",
    "    print(f\"   Revenue: ${sales_df['total_amount'].sum():,.2f}\")\n",
    "    \n",
    "    # Key findings\n",
    "    print(f\"\\n🔍 Key Findings:\")\n",
    "    print(f\"   • Average transaction: ${sales_df['total_amount'].mean():.2f}\")\n",
    "    print(f\"   • Largest transaction: ${sales_df['total_amount'].max():.2f}\")\n",
    "    print(f\"   • Most active region: {sales_df['region'].value_counts().index[0]}\")\n",
    "    print(f\"   • Most popular channel: {sales_df['channel'].value_counts().index[0]}\")\n",
    "    print(f\"   • Unique customers: {sales_df['customer_id'].nunique():,}\")\n",
    "    print(f\"   • Unique products: {sales_df['product_id'].nunique()}\")\n",
    "\n",
    "print(f\"\\n🚀 Next Steps for Tmux Layout Testing:\")\n",
    "print(f\"   1️⃣ Data Window: Use 'fdata' to explore exported files\")\n",
    "print(f\"   2️⃣ REPL Window: Test quickload() and quicktest() functions\")\n",
    "print(f\"   3️⃣ Shell Window: Run data_ingestion.py if database missing\")\n",
    "print(f\"   4️⃣ Editor Window: Edit and test analysis scripts\")\n",
    "print(f\"   5️⃣ Jupyter Window: Run Sales_Analysis.ipynb for full analysis\")\n",
    "\n",
    "print(f\"\\n💡 EDA Functions Tested:\")\n",
    "print(f\"   ✅ quick_profile() - Data overview\")\n",
    "print(f\"   ✅ benchmark_loading() - Performance comparison\")\n",
    "print(f\"   ✅ explore_json() - JSON structure analysis\")\n",
    "print(f\"   ✅ quick_stats() - Statistical overview\")\n",
    "print(f\"   ✅ data_quality_report() - Quality assessment\")\n",
    "print(f\"   ✅ Cross-window integration tests\")\n",
    "\n",
    "print(f\"\\n🎉 EDA Complete! Ready for advanced analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "üî¨ **Quick data exploration and profiling for tmux layout testing**\n",
    "\n",
    "This notebook focuses on:\n",
    "- Rapid data profiling and quality assessment\n",
    "- Interactive data exploration\n",
    "- Testing cross-window workflows\n",
    "- Performance comparisons between tools\n",
    "\n",
    "Perfect for testing the **Data window** and **REPL window** integration!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Quick Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast imports for EDA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import duckdb\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Quick settings\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"Set2\")\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"üî¨ EDA Environment Ready!\")\n",
    "print(f\"Working directory: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÅ File Discovery Test\n",
    "\n",
    "Test data file discovery - simulating Data window workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover available data files (like Data window)\n",
    "print(\"üìÇ Data File Discovery:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "data_dir = Path('../data')\n",
    "if data_dir.exists():\n",
    "    print(\"üìä Available data files:\")\n",
    "    for file_path in data_dir.glob('*'):\n",
    "        if file_path.is_file():\n",
    "            size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "            print(f\"  üìÑ {file_path.name}: {size_mb:.2f} MB\")\n",
    "else:\n",
    "    print(\"‚ùå Data directory not found\")\n",
    "\n",
    "# List by file type (simulating fd commands)\n",
    "print(\"\\nüîç Files by type:\")\n",
    "file_types = {\n",
    "    'CSV': list(data_dir.glob('*.csv')),\n",
    "    'JSON': list(data_dir.glob('*.json')),\n",
    "    'Parquet': list(data_dir.glob('*.parquet')),\n",
    "    'Analysis Results': list(data_dir.glob('analysis_*.csv'))\n",
    "}\n",
    "\n",
    "for file_type, files in file_types.items():\n",
    "    print(f\"  {file_type}: {len(files)} files\")\n",
    "    for file in files[:3]:  # Show first 3\n",
    "        print(f\"    ‚Ä¢ {file.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Quick Data Profiling\n",
    "\n",
    "Rapid data profiling using pandas - test `quickload()` functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick data profiling function (like quickload in REPL)\n",
    "def quick_profile(file_path, sample_size=None):\n",
    "    \"\"\"Quick data profiling - simulates quickload() function.\"\"\"\n",
    "    print(f\"üîç Quick Profile: {file_path}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Load data based on file type\n",
    "        if str(file_path).endswith('.csv'):\n",
    "            df = pd.read_csv(file_path, nrows=sample_size)\n",
    "        elif str(file_path).endswith('.parquet'):\n",
    "            df = pd.read_parquet(file_path)\n",
    "        else:\n",
    "            print(\"‚ùå Unsupported file type\")\n",
    "            return None\n",
    "        \n",
    "        # Basic info\n",
    "        print(f\"üìè Shape: {df.shape}\")\n",
    "        print(f\"üíæ Memory: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "        print(f\"üè∑Ô∏è  Columns: {list(df.columns)}\")\n",
    "        print(f\"üî¢ Data types: {df.dtypes.value_counts().to_dict()}\")\n",
    "        \n",
    "        # Data quality\n",
    "        missing = df.isnull().sum().sum()\n",
    "        duplicates = df.duplicated().sum()\n",
    "        print(f\"‚ùì Missing values: {missing}\")\n",
    "        print(f\"üîÅ Duplicates: {duplicates}\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test with sales data\n",
    "sales_df = quick_profile('../data/sales.csv')\n",
    "if sales_df is not None:\n",
    "    print(\"\\nüëÄ First 3 rows:\")\n",
    "    print(sales_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Performance Comparison\n",
    "\n",
    "Compare loading methods - test DuckDB vs Pandas performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance benchmark (simulating REPL quick tests)\n",
    "import time\n",
    "\n",
    "def benchmark_loading(file_path, iterations=3):\n",
    "    \"\"\"Benchmark different loading methods.\"\"\"\n",
    "    print(f\"‚ö° Performance Benchmark: {Path(file_path).name}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Pandas loading\n",
    "    pandas_times = []\n",
    "    for i in range(iterations):\n",
    "        start = time.time()\n",
    "        df_pandas = pd.read_csv(file_path)\n",
    "        pandas_times.append(time.time() - start)\n",
    "    \n",
    "    results['pandas'] = {\n",
    "        'avg_time': np.mean(pandas_times),\n",
    "        'rows': len(df_pandas),\n",
    "        'memory_mb': df_pandas.memory_usage(deep=True).sum() / 1024**2\n",
    "    }\n",
    "    \n",
    "    # DuckDB loading\n",
    "    duckdb_times = []\n",
    "    for i in range(iterations):\n",
    "        conn = duckdb.connect()\n",
    "        start = time.time()\n",
    "        df_duckdb = conn.execute(f\"SELECT * FROM read_csv_auto('{file_path}')\").df()\n",
    "        duckdb_times.append(time.time() - start)\n",
    "        conn.close()\n",
    "    \n",
    "    results['duckdb'] = {\n",
    "        'avg_time': np.mean(duckdb_times),\n",
    "        'rows': len(df_duckdb),\n",
    "        'memory_mb': df_duckdb.memory_usage(deep=True).sum() / 1024**2\n",
    "    }\n",
    "    \n",
    "    # Results\n",
    "    print(f\"üêº Pandas: {results['pandas']['avg_time']:.4f}s avg ({results['pandas']['rows']:,} rows)\")\n",
    "    print(f\"ü¶Ü DuckDB: {results['duckdb']['avg_time']:.4f}s avg ({results['duckdb']['rows']:,} rows)\")\n",
    "    \n",
    "    speedup = results['pandas']['avg_time'] / results['duckdb']['avg_time']\n",
    "    winner = 'DuckDB' if speedup > 1 else 'Pandas'\n",
    "    print(f\"üèÜ Winner: {winner} ({speedup:.2f}x {'faster' if speedup > 1 else 'slower'})\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run benchmark\n",
    "if Path('../data/sales.csv').exists():\n",
    "    benchmark_results = benchmark_loading('../data/sales.csv')\n",
    "else:\n",
    "    print(\"‚ùå Sales CSV not found for benchmarking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã JSON Structure Exploration\n",
    "\n",
    "Explore nested JSON structure - test complex data handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON exploration (simulating Data window JSON preview)\n",
    "def explore_json(file_path):\n",
    "    \"\"\"Explore JSON structure - like jsonprev() function.\"\"\"\n",
    "    print(f\"üìã JSON Structure: {Path(file_path).name}\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        def analyze_structure(obj, path=\"root\", max_depth=3, current_depth=0):\n",
    "            if current_depth > max_depth:\n",
    "                return\n",
    "            \n",
    "            if isinstance(obj, dict):\n",
    "                print(f\"{'  ' * current_depth}üìÅ {path} (dict, {len(obj)} keys)\")\n",
    "                for key, value in list(obj.items())[:5]:  # First 5 keys\n",
    "                    analyze_structure(value, f\"{path}.{key}\", max_depth, current_depth + 1)\n",
    "                if len(obj) > 5:\n",
    "                    print(f\"{'  ' * (current_depth + 1)}... and {len(obj) - 5} more keys\")\n",
    "            \n",
    "            elif isinstance(obj, list):\n",
    "                print(f\"{'  ' * current_depth}üìä {path} (list, {len(obj)} items)\")\n",
    "                if obj:\n",
    "                    analyze_structure(obj[0], f\"{path}[0]\", max_depth, current_depth + 1)\n",
    "            \n",
    "            else:\n",
    "                type_name = type(obj).__name__\n",
    "                value_preview = str(obj)[:50] + \"...\" if len(str(obj)) > 50 else str(obj)\n",
    "                print(f\"{'  ' * current_depth}üè∑Ô∏è  {path} ({type_name}): {value_preview}\")\n",
    "        \n",
    "        analyze_structure(data)\n",
    "        \n",
    "        # Summary stats\n",
    "        file_size = Path(file_path).stat().st_size\n",
    "        print(f\"\\nüìä JSON Summary:\")\n",
    "        print(f\"  File size: {file_size / 1024:.1f} KB\")\n",
    "        print(f\"  Root type: {type(data).__name__}\")\n",
    "        \n",
    "        if isinstance(data, dict):\n",
    "            print(f\"  Top-level keys: {len(data)}\")\n",
    "        elif isinstance(data, list):\n",
    "            print(f\"  Array length: {len(data)}\")\n",
    "        \n",
    "        return data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading JSON: {e}\")\n",
    "        return None\n",
    "\n",
    "# Explore products JSON\n",
    "if Path('../data/products.json').exists():\n",
    "    products_data = explore_json('../data/products.json')\n",
    "else:\n",
    "    print(\"‚ùå Products JSON not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¢ Statistical Overview\n",
    "\n",
    "Quick statistical analysis - test Data window statistics functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick statistical overview (like quickstats() function)\n",
    "def quick_stats(df, name=\"Dataset\"):\n",
    "    \"\"\"Generate quick statistics overview.\"\"\"\n",
    "    print(f\"üìä Quick Stats: {name}\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        print(\"üî¢ Numeric Columns:\")\n",
    "        for col in numeric_cols:\n",
    "            print(f\"  {col}:\")\n",
    "            print(f\"    Range: {df[col].min():.2f} to {df[col].max():.2f}\")\n",
    "            print(f\"    Mean: {df[col].mean():.2f}\")\n",
    "            print(f\"    Std: {df[col].std():.2f}\")\n",
    "            print(f\"    Missing: {df[col].isnull().sum()}\")\n",
    "    \n",
    "    # Categorical columns\n",
    "    cat_cols = df.select_dtypes(include=['object']).columns\n",
    "    if len(cat_cols) > 0:\n",
    "        print(\"\\nüìù Categorical Columns:\")\n",
    "        for col in cat_cols:\n",
    "            unique_count = df[col].nunique()\n",
    "            print(f\"  {col}: {unique_count} unique values\")\n",
    "            if unique_count <= 10:  # Show values if not too many\n",
    "                top_values = df[col].value_counts().head(3)\n",
    "                print(f\"    Top: {dict(top_values)}\")\n",
    "    \n",
    "    return df.describe(include='all')\n",
    "\n",
    "# Quick stats on sales data\n",
    "if 'sales_df' in locals() and sales_df is not None:\n",
    "    stats = quick_stats(sales_df, \"Sales Data\")\n",
    "    print(\"\\nüìã Full Description:\")\n",
    "    print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Quick Visualizations\n",
    "\n",
    "Rapid visualization for data understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick visualization function\n",
    "def quick_viz(df, max_cols=4):\n",
    "    \"\"\"Generate quick visualizations for EDA.\"\"\"\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns[:max_cols]\n",
    "    \n",
    "    if len(numeric_cols) == 0:\n",
    "        print(\"‚ùå No numeric columns for visualization\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    fig.suptitle('Quick EDA Visualizations', fontsize=14)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, col in enumerate(numeric_cols):\n",
    "        if i >= 4:\n",
    "            break\n",
    "        \n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Histogram with KDE\n",
    "        df[col].hist(ax=ax, bins=20, alpha=0.7, edgecolor='black')\n",
    "        ax.set_title(f'{col} Distribution')\n",
    "        ax.set_xlabel(col)\n",
    "        ax.set_ylabel('Frequency')\n",
    "        \n",
    "        # Add statistics text\n",
    "        mean_val = df[col].mean()\n",
    "        std_val = df[col].std()\n",
    "        ax.axvline(mean_val, color='red', linestyle='--', alpha=0.7, label=f'Mean: {mean_val:.2f}')\n",
    "        ax.legend()\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(len(numeric_cols), 4):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate quick visualizations\n",
    "if 'sales_df' in locals() and sales_df is not None:\n",
    "    quick_viz(sales_df)\n",
    "else:\n",
    "    print(\"‚ùå No data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Data Quality Assessment\n",
    "\n",
    "Comprehensive data quality analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality assessment (like datainfo() function)\n",
    "def data_quality_report(df, name=\"Dataset\"):\n",
    "    \"\"\"Comprehensive data quality assessment.\"\"\"\n",
    "    print(f\"üîç Data Quality Report: {name}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"üìè Dimensions: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "    print(f\"üíæ Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Data types\n",
    "    print(f\"\\nüè∑Ô∏è  Data Types:\")\n",
    "    type_counts = df.dtypes.value_counts()\n",
    "    for dtype, count in type_counts.items():\n",
    "        print(f\"  {dtype}: {count} columns\")\n",
    "    \n",
    "    # Missing data analysis\n",
    "    print(f\"\\n‚ùì Missing Data Analysis:\")\n",
    "    missing_data = df.isnull().sum()\n",
    "    missing_pct = (missing_data / len(df)) * 100\n",
    "    \n",
    "    has_missing = missing_data[missing_data > 0]\n",
    "    if len(has_missing) > 0:\n",
    "        print(\"  Columns with missing data:\")\n",
    "        for col, missing_count in has_missing.items():\n",
    "            pct = missing_pct[col]\n",
    "            print(f\"    {col}: {missing_count} ({pct:.1f}%)\")\n",
    "    else:\n",
    "        print(\"  ‚úÖ No missing data found\")\n",
    "    \n",
    "    # Duplicate analysis\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    duplicate_pct = (duplicate_count / len(df)) * 100\n",
    "    print(f\"\\nüîÅ Duplicates: {duplicate_count} ({duplicate_pct:.1f}%)\")\n",
    "    \n",
    "    # Unique value analysis\n",
    "    print(f\"\\nüéØ Uniqueness Analysis:\")\n",
    "    for col in df.columns:\n",
    "        unique_count = df[col].nunique()\n",
    "        unique_pct = (unique_count / len(df)) * 100\n",
    "        \n",
    "        if unique_count == len(df):\n",
    "            status = \"üîë Unique identifier\"\n",
    "        elif unique_count == 1:\n",
    "            status = \"‚ö†Ô∏è  Constant value\"\n",
    "        elif unique_count < 10:\n",
    "            status = \"üìä Categorical\"\n",
    "        elif unique_pct > 95:\n",
    "            status = \"üî¢ High cardinality\"\n",
    "        else:\n",
    "            status = \"üìà Normal distribution\"\n",
    "        \n",
    "        print(f\"  {col}: {unique_count:,} unique ({unique_pct:.1f}%) - {status}\")\n",
    "    \n",
    "    # Data quality score\n",
    "    quality_score = 100\n",
    "    if duplicate_count > 0:\n",
    "        quality_score -= min(duplicate_pct * 2, 20)  # Max 20 point deduction\n",
    "    \n",
    "    missing_penalty = min(missing_pct.max() * 1.5, 30)  # Max 30 point deduction\n",
    "    quality_score -= missing_penalty\n",
    "    \n",
    "    print(f\"\\nüèÜ Data Quality Score: {quality_score:.1f}/100\")\n",
    "    \n",
    "    if quality_score >= 90:\n",
    "        print(\"   ‚úÖ Excellent data quality\")\n",
    "    elif quality_score >= 75:\n",
    "        print(\"   ‚ö†Ô∏è  Good data quality with minor issues\")\n",
    "    elif quality_score >= 50:\n",
    "        print(\"   üîß Fair data quality - needs attention\")\n",
    "    else:\n",
    "        print(\"   üö® Poor data quality - significant issues\")\n",
    "    \n",
    "    return {\n",
    "        'shape': df.shape,\n",
    "        'missing_data': missing_data.to_dict(),\n",
    "        'duplicates': duplicate_count,\n",
    "        'quality_score': quality_score\n",
    "    }\n",
    "\n",
    "# Run data quality assessment\n",
    "if 'sales_df' in locals() and sales_df is not None:\n",
    "    quality_report = data_quality_report(sales_df, \"Sales Transactions\")\n",
    "else:\n",
    "    print(\"‚ùå No data available for quality assessment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Cross-Window Testing\n",
    "\n",
    "Test integration with other tmux layout windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-window integration test\n",
    "print(\"üîó Cross-Window Integration Test\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# 1. Test database connection (Shell/REPL window integration)\n",
    "print(\"1Ô∏è‚É£ Testing database connection:\")\n",
    "try:\n",
    "    conn = duckdb.connect('sales_analysis.duckdb')\n",
    "    tables = conn.execute(\"SHOW TABLES\").fetchall()\n",
    "    if tables:\n",
    "        print(f\"   ‚úÖ Connected to database with {len(tables)} tables\")\n",
    "        for table in tables:\n",
    "            count = conn.execute(f\"SELECT COUNT(*) FROM {table[0]}\").fetchone()[0]\n",
    "            print(f\"      ‚Ä¢ {table[0]}: {count:,} rows\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  Database exists but no tables found\")\n",
    "        print(\"   üí° Run data_ingestion.py in Shell window first\")\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Database connection failed: {e}\")\n",
    "    print(\"   üí° Create database using scripts/data_ingestion.py\")\n",
    "\n",
    "# 2. Test file accessibility (Data window integration)\n",
    "print(\"\\n2Ô∏è‚É£ Testing file accessibility:\")\n",
    "test_files = [\n",
    "    '../data/sales.csv',\n",
    "    '../data/products.json',\n",
    "    '../data/regions.parquet',\n",
    "    '../scripts/test_functions.py'\n",
    "]\n",
    "\n",
    "for file_path in test_files:\n",
    "    if Path(file_path).exists():\n",
    "        size = Path(file_path).stat().st_size / 1024\n",
    "        print(f\"   ‚úÖ {Path(file_path).name}: {size:.1f} KB\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå {Path(file_path).name}: Not found\")\n",
    "\n",
    "# 3. Test function imports (REPL window integration)\n",
    "print(\"\\n3Ô∏è‚É£ Testing function imports:\")\n",
    "try:\n",
    "    import sys\n",
    "    sys.path.append('../scripts')\n",
    "    \n",
    "    from test_functions import validate_transaction_data, calculate_profit_metrics\n",
    "    print(\"   ‚úÖ Successfully imported test functions\")\n",
    "    \n",
    "    # Test a function\n",
    "    test_result = calculate_profit_metrics(100, 60, 2)\n",
    "    print(f\"   ‚úÖ Function test successful: profit = ${test_result['total_profit']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Function import failed: {e}\")\n",
    "\n",
    "# 4. Test data export (Editor window integration)\n",
    "print(\"\\n4Ô∏è‚É£ Testing data export:\")\n",
    "if 'sales_df' in locals() and sales_df is not None:\n",
    "    try:\n",
    "        # Export sample for Editor window\n",
    "        sample_df = sales_df.head(10)\n",
    "        sample_df.to_csv('../data/eda_sample_export.csv', index=False)\n",
    "        print(\"   ‚úÖ Sample data exported to eda_sample_export.csv\")\n",
    "        print(\"   üí° Use 'fdata' in Data window to find this file\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Export failed: {e}\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è  No data available for export\")\n",
    "\n",
    "print(\"\\nüéØ Integration Test Summary:\")\n",
    "print(\"   ‚Ä¢ Database: Ready for REPL SQL queries\")\n",
    "print(\"   ‚Ä¢ Files: Available for Data window exploration\")\n",
    "print(\"   ‚Ä¢ Functions: Ready for REPL quick testing\")\n",
    "print(\"   ‚Ä¢ Exports: Available for Editor window analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã EDA Summary\n",
    "\n",
    "Summary of findings and next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA Summary and recommendations\n",
    "print(\"üìã EDA Summary Report\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if 'sales_df' in locals() and sales_df is not None:\n",
    "    print(f\"üìä Dataset: Sales Transactions\")\n",
    "    print(f\"   Records: {len(sales_df):,}\")\n",
    "    print(f\"   Columns: {len(sales_df.columns)}\")\n",
    "    print(f\"   Date range: {sales_df['date'].min()} to {sales_df['date'].max()}\")\n",
    "    print(f\"   Revenue: ${sales_df['total_amount'].sum():,.2f}\")\n",
    "    \n",
    "    # Key findings\n",
    "    print(f\"\\nüîç Key Findings:\")\n",
    "    print(f\"   ‚Ä¢ Average transaction: ${sales_df['total_amount'].mean():.2f}\")\n",
    "    print(f\"   ‚Ä¢ Largest transaction: ${sales_df['total_amount'].max():.2f}\")\n",
    "    print(f\"   ‚Ä¢ Most active region: {sales_df['region'].value_counts().index[0]}\")\n",
    "    print(f\"   ‚Ä¢ Most popular channel: {sales_df['channel'].value_counts().index[0]}\")\n",
    "    print(f\"   ‚Ä¢ Unique customers: {sales_df['customer_id'].nunique():,}\")\n",
    "    print(f\"   ‚Ä¢ Unique products: {sales_df['product_id'].nunique()}\")\n",
    "\n",
    "print(f\"\\nüöÄ Next Steps for Tmux Layout Testing:\")\n",
    "print(f\"   1Ô∏è‚É£ Data Window: Use 'fdata' to explore exported files\")\n",
    "print(f\"   2Ô∏è‚É£ REPL Window: Test quickload() and quicktest() functions\")\n",
    "print(f\"   3Ô∏è‚É£ Shell Window: Run data_ingestion.py if database missing\")\n",
    "print(f\"   4Ô∏è‚É£ Editor Window: Edit and test analysis scripts\")\n",
    "print(f\"   5Ô∏è‚É£ Jupyter Window: Run Sales_Analysis.ipynb for full analysis\")\n",
    "\n",
    "print(f\"\\nüí° EDA Functions Tested:\")\n",
    "print(f\"   ‚úÖ quick_profile() - Data overview\")\n",
    "print(f\"   ‚úÖ benchmark_loading() - Performance comparison\")\n",
    "print(f\"   ‚úÖ explore_json() - JSON structure analysis\")\n",
    "print(f\"   ‚úÖ quick_stats() - Statistical overview\")\n",
    "print(f\"   ‚úÖ data_quality_report() - Quality assessment\")\n",
    "print(f\"   ‚úÖ Cross-window integration tests\")\n",
    "\n",
    "print(f\"\\nüéâ EDA Complete! Ready for advanced analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
